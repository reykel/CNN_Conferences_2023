{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3FeKSSRgvb9GMsABnsQ4Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reykel/machine_learning_keras_tf_owned/blob/main/01-data_augmentation_dogs_cats.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "in3OdvpUG_9_"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1WtoaOHVrVh"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ede3_kbeHOjR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras import callbacks"
      ],
      "metadata": {
        "id": "J6OrCDpc8-rH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "NBYKIwNv1LOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train_examples, validation_examples, test_examples), info = tfds.load(\n",
        "    'cats_vs_dogs',\n",
        "    shuffle_files=True, \n",
        "    with_info=True, \n",
        "    as_supervised=True, \n",
        "    split=['train[:80%]', 'train[80%:95%]', 'train[95%:]'],\n",
        "    )\n",
        "\n",
        "num_examples = info.splits['train'].num_examples\n",
        "num_classes = info.features['label'].num_classes"
      ],
      "metadata": {
        "id": "SPgCscy01Li-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NqNselLVrWA"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 100\n",
        "IMG_SIZE = 150\n",
        "EPOCHS = 100"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = train_examples.map(lambda x, y: (tf.image.resize(x, (IMG_SIZE, IMG_SIZE)), y))\n",
        "val_ds = validation_examples.map(lambda x, y: (tf.image.resize(x, (IMG_SIZE, IMG_SIZE)), y))\n",
        "test_ds = test_examples.map(lambda x, y: (tf.image.resize(x, (IMG_SIZE, IMG_SIZE)), y))"
      ],
      "metadata": {
        "id": "fH42Bkce8WdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [layers.RandomFlip('horizontal'), \n",
        "    layers.RandomRotation(factor=(-0.025, 0.025)),\n",
        "    layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
        "    layers.RandomContrast(factor=0.1),\n",
        "])"
      ],
      "metadata": {
        "id": "N_8lvDP980YL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "earlystopping = callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=5, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "5fdmUzyyMv30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = train_ds.batch(batch_size=BATCH_SIZE, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "val_ds = val_ds.batch(batch_size=BATCH_SIZE, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
        "                      \n",
        "test_ds = test_ds.batch(batch_size=BATCH_SIZE, drop_remainder=True).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "VrmwI-Dz-3p_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "Evjf8jZk2zi-"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    data_augmentation,\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(2, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b66qAJF_4Jnw"
      },
      "outputs": [],
      "source": [
        "model.build([None, IMG_SIZE, IMG_SIZE, 3])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "  optimizer= tf.keras.optimizers.Adam(0.001),\n",
        "  loss='sparse_categorical_crossentropy',\n",
        "  metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "60oAjXPti146"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_ds, epochs=EPOCHS, validation_data=val_ds, verbose=1, callbacks =[earlystopping])"
      ],
      "metadata": {
        "id": "X099LrSQi7jB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_batch, label_batch = next(iter(test_ds.take(1)))\n",
        "image_batch = image_batch.numpy()\n",
        "label_batch = label_batch.numpy()"
      ],
      "metadata": {
        "id": "DoKUbOqS0dTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_batch = model.predict(image_batch)"
      ],
      "metadata": {
        "id": "VJTFhp011Q75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_ids = np.argmax(predicted_batch, axis=-1)\n",
        "\n",
        "for i in range(0,len(predicted_ids)):\n",
        "  print(str(predicted_ids[i]) + \" - \" + str(label_batch[i]))"
      ],
      "metadata": {
        "id": "kINHNS1n1WdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(label_batch, predicted_ids)"
      ],
      "metadata": {
        "id": "g8ABpQqn1ang"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "metadata": {
        "id": "gi6sYZ9b1d5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm_plot_labels = ['Cats','Dogs']\n",
        "plot_confusion_matrix(cm, cm_plot_labels, title='Confusion Matrix')"
      ],
      "metadata": {
        "id": "aR_we9CZ1jtp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}